# ‚ö†Ô∏è IMPORTANT WARNING ‚ö†Ô∏è
**THIS PROGRAM IS INTENDED SOLELY FOR EDUCATIONAL PURPOSES DURING THE "TURKCELL GELECEƒûƒ∞ YAZANLAR PENTESTING 101" COURSE. IT WAS WRITTEN TO DEMONSTRATE MY CODING AND ALGORITHM DEVELOPMENT SKILLS. ANY USE OF THIS CODE IS THE SOLE RESPONSIBILITY OF THE USER. THE USER ASSUMES ALL LEGAL LIABILITY FOR ANY ACTIONS TAKEN WITH THIS CODE. THE AUTHOR BEARS NO LEGAL LIABILITY FOR ANY CONSEQUENCES ARISING FROM THE USE OF THIS PROGRAM. BY USING THIS PROGRAM, YOU AGREE TO THESE TERMS AND ACCEPT ALL RESPONSIBILITY.**
**THIS PROGRAM CAN CAUSE WEBSITES TO CRASH OR YOUR IP ADDRESS TO BE BANNED. PLEASE DO NOT USE IT FOR FUN. ONLY USE IT AFTER OBTAINING PERMISSION FROM THE WEBSITE OWNERS AND SET THE SPEED TO LEVEL 3.**

----

<h1 align="center">Spider-Crawl</h1>
<h3 align="center">A Simple Web Crawler with Adjustable Crawling Speed</h3>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.x-blue.svg" alt="Python 3.x">
  <img src="https://img.shields.io/badge/Requests-2.x-blue.svg" alt="Requests 2.x">
  <img src="https://img.shields.io/badge/BeautifulSoup-4.x-blue.svg" alt="BeautifulSoup 4.x">
</p>

---

<p align="center">This project is a simple web crawler that allows users to input a target URL and select the crawling speed. The crawler will recursively scan the target website and print out all discovered URLs.</p>

## üöÄ Features

- **Adjustable Crawling Speed:** Choose between three speed levels to avoid being banned by the target site.
- **Recursive Crawling:** Automatically follow and crawl discovered links within the same domain.
- **Clean and Structured Code:** Well-commented and easy to understand.

## üìã Requirements

- Python 3.x
- `requests` library
- `beautifulsoup4` library
- `pyfiglet` library

## üì¶ Installation

1. **Clone the repository:**
    ```sh
    git clone https://github.com/EGuseinov/Spider-Crawl-SimpleWebCrawler.git
    ```

2. **Install the required libraries:**
    ```sh
    pip install requests beautifulsoup4 pyfiglet
    ```

## üõ† Usage


1. **Run the crawler:**
    ```sh
    python spidercrawl.py
    ```

2. **Follow the prompts to input the target URL and select the crawling speed.**
    - **Level 1:** Delay between requests is 0 to 1 second.
    - **Level 2:** Delay between requests is 1 to 3 seconds.
    - **Level 3:** Delay between requests is 3 to 5 seconds. (RECOMENDED)

## üåê Example

Here's an example of how to run the crawler:

```sh
Please enter the target URL (e.g., https://www.example.com): 
Please select crawling speed level (1, 2, or 3): 2
Successfully connected to the site.
Found URL: https://www.example.com/...
```
üìû Connect with Me
<p align="left">
  <a href="https://linkedin.com/in/elvinguseinov" target="_blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg" alt="linkedin" height="30" width="40" /></a>
  <a href="https://instagram.com/eguseinow" target="_blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/instagram.svg" alt="instagram" height="30" width="40" /></a>
</p>
üõ† Languages and Tools
<p align="left">
  <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> 
  <a href="https://www.w3.org/html/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/html5/html5-original-wordmark.svg" alt="html5" width="40" height="40"/> </a> 
  <a href="https://www.linux.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg" alt="linux" width="40" height="40"/> </a>
</p>

